{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KnuthMorrisPratt(text, pattern):\n",
    "\n",
    "    '''Yields all starting positions of copies of the pattern in the text.\n",
    "Calling conventions are similar to string.find, but its arguments can be\n",
    "lists or iterators, not just strings, it returns all matches, not just\n",
    "the first one, and it does not need the whole text in memory at once.\n",
    "Whenever it yields, it will have read the text exactly up to and including\n",
    "the match that caused the yield.'''\n",
    "\n",
    "    # allow indexing into pattern and protect against change during yield\n",
    "    pattern = list(pattern)\n",
    "\n",
    "    # build table of shift amounts\n",
    "    shifts = [1] * (len(pattern) + 1)\n",
    "    shift = 1\n",
    "    for pos in range(len(pattern)):\n",
    "        while shift <= pos and pattern[pos] != pattern[pos-shift]:\n",
    "            shift += shifts[pos-shift]\n",
    "        shifts[pos+1] = shift\n",
    "\n",
    "    print(shifts)\n",
    "    # do the actual search\n",
    "    startPos = 0\n",
    "    matchLen = 0\n",
    "    for c in text:\n",
    "        while matchLen == len(pattern) or \\\n",
    "              matchLen >= 0 and pattern[matchLen] != c:\n",
    "            startPos += shifts[matchLen]\n",
    "            matchLen -= shifts[matchLen]\n",
    "        matchLen += 1\n",
    "        if matchLen == len(pattern):\n",
    "            yield startPos\n",
    "\n",
    "def search_list(text, pattern):\n",
    "    matchLen = len(pattern)\n",
    "    for i in range(len(text) - matchLen + 1):\n",
    "        startPos = 0\n",
    "        while(startPos < matchLen and text[i + startPos] == pattern[startPos]):\n",
    "            startPos += 1\n",
    "        #if (text[i:i+matchLen] == pattern): return i\n",
    "        if (startPos == matchLen): return i\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_dict = {}\n",
    "vocab_list = []\n",
    "review_lines = []\n",
    "\n",
    "i = 0\n",
    "#with open('reviews_test.txt') as f:\n",
    "with open('reviews_sample.txt') as f: \n",
    "    for line in f.read().splitlines():\n",
    "        vocab_index = \"\"\n",
    "        for word in line.split(' '):\n",
    "            if word not in vocab_dict:                \n",
    "                vocab_dict[word] = i\n",
    "                word_index = i\n",
    "                vocab_list.append(word)\n",
    "                i += 1\n",
    "            else:\n",
    "                word_index = vocab_dict[word]\n",
    "            \n",
    "            vocab_index += \":\" + str(word_index)\n",
    "        \n",
    "        vocab_index += \":\"\n",
    "        review_lines.append(vocab_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 22104/22104 [02:21<00:00, 156.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "MIN_SUPPORT = len(review_lines) * 0.01\n",
    "\n",
    "def get_support(all_reviews, pattern):\n",
    "    str_pattern = \"\"\n",
    "    for i in pattern:\n",
    "        str_pattern += \":\" + str(i)\n",
    "    str_pattern += \":\"\n",
    "    \n",
    "    support = 0\n",
    "    \n",
    "    for review in all_reviews:\n",
    "        #if search_list(review, pattern) >= 0:\n",
    "        if review.find(str_pattern) >= 0:\n",
    "            support += 1\n",
    "    \n",
    "    return support\n",
    "\n",
    "L = []\n",
    "S = []\n",
    "L1 = []\n",
    "S1 = []\n",
    "for vocab in tqdm(range(len(vocab_list))):\n",
    "    s = get_support(review_lines, [vocab])    \n",
    "    if(s >= MIN_SUPPORT):\n",
    "        L1.append([vocab])\n",
    "        S1.append(s)\n",
    "\n",
    "L.append(L1)\n",
    "S.append(S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def apriori_gen(all_lines, LK_1, min_support):\n",
    "    LK = []\n",
    "    S = []\n",
    "    for l1 in tqdm(LK_1):\n",
    "        for l2 in LK_1:\n",
    "            if l1[:-1] == l2[:-1] and l1[-1] < l2[-1]:\n",
    "                l = l1 + [l2[-1]]\n",
    "                support = get_support(all_lines, l)\n",
    "                if support >= min_support:\n",
    "                    print(l)\n",
    "                    print(support)\n",
    "                    print([vocab_list[i] for i in l])\n",
    "                    LK.append(l)\n",
    "                    S.append(support)\n",
    "    \n",
    "    return LK, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 1-Itemsets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                               | 4/977 [00:22<1:30:34,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8]\n",
      "170\n",
      "['year', 'ago']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                              | 10/977 [00:57<1:37:18,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 32]\n",
      "246\n",
      "['food', 'good']\n",
      "[16, 39]\n",
      "118\n",
      "['food', 'service']\n",
      "[16, 45]\n",
      "163\n",
      "['food', 'great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                             | 23/977 [02:11<1:27:42,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 39]\n",
      "147\n",
      "['good', 'service']\n",
      "[32, 46]\n",
      "109\n",
      "['good', 'place']\n",
      "[32, 77]\n",
      "108\n",
      "['good', 'thing']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                             | 26/977 [02:27<1:26:51,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 39]\n",
      "209\n",
      "['customer', 'service']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▏                                                                            | 27/977 [02:33<1:26:29,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39, 45]\n",
      "135\n",
      "['service', 'great']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                            | 32/977 [02:59<1:24:24,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 46]\n",
      "273\n",
      "['great', 'place']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▋                                                                            | 33/977 [03:05<1:24:33,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 250]\n",
      "131\n",
      "['place', 'get']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                            | 38/977 [03:32<1:25:03,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 93]\n",
      "154\n",
      "['staff', 'friendly']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                           | 42/977 [03:54<1:24:17,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 309]\n",
      "211\n",
      "['make', 'sure']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                           | 47/977 [04:20<1:22:24,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65, 66]\n",
      "220\n",
      "['ice', 'cream']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                           | 49/977 [04:30<1:21:16,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 91]\n",
      "111\n",
      "['really', 'nice']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▋                                                                         | 70/977 [06:19<1:16:56,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 128]\n",
      "130\n",
      "['would', 'definitely']\n",
      "[101, 177]\n",
      "133\n",
      "['would', 'recommend']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                       | 93/977 [08:23<1:20:11,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 391]\n",
      "140\n",
      "['definitely', 'back']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▌                                                                       | 94/977 [08:29<1:20:15,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129, 391]\n",
      "237\n",
      "['come', 'back']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▎                                                                     | 104/977 [09:23<1:18:20,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140, 141]\n",
      "141\n",
      "['pretty', 'much']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▌                                                                     | 107/977 [09:39<1:17:31,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143, 1500]\n",
      "125\n",
      "['hot', 'dog']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████                                                                     | 113/977 [10:11<1:16:35,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151, 152]\n",
      "107\n",
      "['fish', 'sandwich']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▊                                                                   | 136/977 [12:10<1:12:20,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176, 177]\n",
      "215\n",
      "['highly', 'recommend']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▎                                                               | 180/977 [15:46<1:03:50,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248, 391]\n",
      "152\n",
      "['going', 'back']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                              | 194/977 [16:52<1:01:01,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[275, 368]\n",
      "253\n",
      "['even', 'though']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▎                                                              | 211/977 [18:09<57:26,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313, 5601]\n",
      "153\n",
      "['strip', 'district']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▎                                                             | 224/977 [19:08<55:46,  4.44s/it]"
     ]
    }
   ],
   "source": [
    "LK_1 = L1\n",
    "while len(LK_1) > 0:\n",
    "    print(\"Working on %d-Itemsets\" % len(LK_1[0]))\n",
    "    LK_1, SK_1 = apriori_gen(review_lines, LK_1, MIN_SUPPORT)\n",
    "    if (len(LK_1) > 0):\n",
    "        L.append(LK_1)\n",
    "        S.append(SK_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('patterns.txt', 'w') as f:\n",
    "    for i in range(len(L)):\n",
    "        for j in range(len(L[i]))\n",
    "            f.write(\"%d:\"%(S[i][j]))\n",
    "            for k in range(len(L[i][j] - 1)):\n",
    "                f.write(\"%s;\"%(vocab_list[L[i][j][k]]))\n",
    "            f.write(\"%s\\n\"%(vocab_list[L[i][j][len(L[i][j] - 1)]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
